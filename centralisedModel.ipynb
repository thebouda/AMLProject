{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pOIPm-AJwPJ6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from lenet5 import LeNet\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Parameters "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if cuda is available\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Model Training Parameters\n",
        "EPOCHS = 100\n",
        "LEARNING_RATE = 2e-3\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Save plots in the folder ./plots or show them\n",
        "SAVE_PLOTS = False\n",
        "\n",
        "\n",
        "# Use batch normalization or not\n",
        "BATCH_NORM = False \n",
        "# group normalization\n",
        "GROUP_NORM = True \n",
        "\n",
        "# group normalization parameters\n",
        "groupNormParams= {\n",
        "'groupNL1' : 2,\n",
        "'groupNL2' :2\n",
        "}\n",
        "\n",
        "\n",
        "if GROUP_NORM ==True & BATCH_NORM ==True:\n",
        "    print(\" Cannot have group an batch normalization True at the same time\")\n",
        "    exit()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training and Validation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SyrXscPNxhol"
      },
      "outputs": [],
      "source": [
        "def train(train_loader, model, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for X, y_target in train_loader:\n",
        "\n",
        "        # Set gradient to zero\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # If there is a GPU, pass the data to the GPU\n",
        "\n",
        "        X = X.to(device)\n",
        "        y_target = y_target.to(device)\n",
        "\n",
        "        # Prediction\n",
        "\n",
        "        # Call model forward()\n",
        "        y_predict, _ = model(X)\n",
        "\n",
        "        # Get loss\n",
        "        loss = criterion(y_predict, y_target)\n",
        "        running_loss += loss.item() * X.size(0)\n",
        "\n",
        "        # Adjusting weights\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    return model, optimizer, epoch_loss\n",
        "\n",
        "\n",
        "def test(valid_loader, model, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "\n",
        "    for X, y_target in valid_loader:\n",
        "        # If there is a GPU\n",
        "\n",
        "        X = X.to(device)\n",
        "        y_target = y_target.to(device)\n",
        "\n",
        "        # Prediction and loss\n",
        "\n",
        "        # Call model forward()\n",
        "        y_predict, _ = model(X)\n",
        "        \n",
        "        # Get loss\n",
        "        loss = criterion(y_predict, y_target)\n",
        "        running_loss += loss.item() * X.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
        "    return model, epoch_loss\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader, device):\n",
        "    '''\n",
        "    Function for computing the accuracy of the predictions over the entire data_loader\n",
        "    '''\n",
        "\n",
        "    correct_pred = 0\n",
        "    n = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for X, y_true in data_loader:\n",
        "\n",
        "            X = X.to(device)\n",
        "            y_true = y_true.to(device)\n",
        "\n",
        "            _, y_prob = model(X)\n",
        "            _, predicted_labels = torch.max(y_prob, 1)\n",
        "\n",
        "            n += y_true.size(0)\n",
        "            correct_pred += (predicted_labels == y_true).sum()\n",
        "\n",
        "    return correct_pred.float() / n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def training_loop(model, criterion, optimizer, train_loader, test_loader,\n",
        "                  epochs, device, print_every=1):\n",
        "\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "\n",
        "    train_accuracies = []\n",
        "    valid_accuracies = []\n",
        "\n",
        "    # Train model\n",
        "    for epoch in range(epochs):\n",
        "        model, optimizer, train_loss = train(train_loader, model,\n",
        "                                             criterion, optimizer, device)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # Validation\n",
        "\n",
        "        # Disable gradient calculation to save memory\n",
        "        with torch.no_grad():\n",
        "            model, valid_loss = test(test_loader, model, criterion, device)\n",
        "            valid_losses.append(valid_loss)\n",
        "\n",
        "        if epoch % print_every == (print_every - 1):\n",
        "            train_acc = get_accuracy(model, train_loader, device)\n",
        "            valid_acc = get_accuracy(model, test_loader, device)\n",
        "\n",
        "            train_accuracies.append(train_acc)\n",
        "            valid_accuracies.append(valid_acc)\n",
        "\n",
        "            print(f'Epoch: {epoch}\\t'\n",
        "                  f'Train loss: {train_loss:.4f}\\t'\n",
        "                  f'Valid loss: {valid_loss:.4f}\\t'\n",
        "                  f'Train accuracy: {100 * train_acc:.2f}\\t'\n",
        "                  f'Valid accuracy: {100 * valid_acc:.2f}')\n",
        "\n",
        "    return model, optimizer, (train_losses, valid_losses), (train_accuracies, valid_accuracies)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loaders and Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fFZ49UhVxna4"
      },
      "outputs": [],
      "source": [
        "# Image augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Normalizing the test images\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Loading CIFAR10 using torchvision.datasets\n",
        "traindata = datasets.CIFAR10('./data', train=True, download=False,\n",
        "                             transform=transform_train)\n",
        "\n",
        "# Creating a pytorch loader for a Deep Learning model\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    traindata, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Loading the test images and thus converting them into a test_loader\n",
        "test_loader = torch.utils.data.DataLoader(datasets.CIFAR10('./data', train=False,\n",
        "                                                           transform=transforms.Compose([transforms.ToTensor(),\n",
        "                                                                                         transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "                                                           ), batch_size=BATCH_SIZE, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--l17eNixqMf",
        "outputId": "3e366c82-bd9a-4ece-dda5-e0e9b0b72f62"
      },
      "outputs": [],
      "source": [
        "model = LeNet(BATCH_NORM,GROUP_NORM,groupNormParams).to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\tTrain loss: 2.0217\tValid loss: 1.7309\tTrain accuracy: 36.16\tValid accuracy: 38.99\n",
            "Epoch: 1\tTrain loss: 1.6558\tValid loss: 1.4766\tTrain accuracy: 43.51\tValid accuracy: 46.31\n",
            "Epoch: 2\tTrain loss: 1.4880\tValid loss: 1.3472\tTrain accuracy: 47.37\tValid accuracy: 50.51\n",
            "Epoch: 3\tTrain loss: 1.3784\tValid loss: 1.2484\tTrain accuracy: 50.94\tValid accuracy: 54.49\n",
            "Epoch: 4\tTrain loss: 1.2999\tValid loss: 1.4648\tTrain accuracy: 44.78\tValid accuracy: 49.43\n",
            "Epoch: 5\tTrain loss: 1.2380\tValid loss: 1.1406\tTrain accuracy: 54.87\tValid accuracy: 58.09\n",
            "Epoch: 6\tTrain loss: 1.1873\tValid loss: 1.0942\tTrain accuracy: 56.83\tValid accuracy: 60.89\n",
            "Epoch: 7\tTrain loss: 1.1495\tValid loss: 1.0431\tTrain accuracy: 59.36\tValid accuracy: 62.19\n",
            "Epoch: 8\tTrain loss: 1.1121\tValid loss: 1.0168\tTrain accuracy: 59.82\tValid accuracy: 64.37\n",
            "Epoch: 9\tTrain loss: 1.0839\tValid loss: 1.0434\tTrain accuracy: 59.29\tValid accuracy: 62.31\n",
            "Epoch: 10\tTrain loss: 1.0585\tValid loss: 0.9456\tTrain accuracy: 63.09\tValid accuracy: 66.81\n",
            "Epoch: 11\tTrain loss: 1.0350\tValid loss: 0.9644\tTrain accuracy: 61.67\tValid accuracy: 66.19\n",
            "Epoch: 12\tTrain loss: 1.0119\tValid loss: 0.9909\tTrain accuracy: 61.30\tValid accuracy: 64.74\n",
            "Epoch: 13\tTrain loss: 0.9903\tValid loss: 0.9359\tTrain accuracy: 62.86\tValid accuracy: 66.96\n",
            "Epoch: 14\tTrain loss: 0.9680\tValid loss: 0.9105\tTrain accuracy: 64.38\tValid accuracy: 67.88\n",
            "Epoch: 15\tTrain loss: 0.9518\tValid loss: 0.9124\tTrain accuracy: 65.57\tValid accuracy: 68.75\n",
            "Epoch: 16\tTrain loss: 0.9368\tValid loss: 0.9665\tTrain accuracy: 62.50\tValid accuracy: 65.41\n",
            "Epoch: 17\tTrain loss: 0.9238\tValid loss: 0.8324\tTrain accuracy: 67.08\tValid accuracy: 70.46\n",
            "Epoch: 18\tTrain loss: 0.9065\tValid loss: 0.8649\tTrain accuracy: 66.44\tValid accuracy: 69.10\n",
            "Epoch: 19\tTrain loss: 0.8924\tValid loss: 0.8019\tTrain accuracy: 68.89\tValid accuracy: 71.59\n",
            "Epoch: 20\tTrain loss: 0.8797\tValid loss: 0.8463\tTrain accuracy: 67.09\tValid accuracy: 69.15\n",
            "Epoch: 21\tTrain loss: 0.8620\tValid loss: 0.7976\tTrain accuracy: 69.51\tValid accuracy: 72.47\n",
            "Epoch: 22\tTrain loss: 0.8517\tValid loss: 0.8721\tTrain accuracy: 66.46\tValid accuracy: 68.80\n",
            "Epoch: 23\tTrain loss: 0.8427\tValid loss: 0.8055\tTrain accuracy: 69.70\tValid accuracy: 72.12\n",
            "Epoch: 24\tTrain loss: 0.8351\tValid loss: 0.7442\tTrain accuracy: 72.10\tValid accuracy: 74.40\n",
            "Epoch: 25\tTrain loss: 0.8173\tValid loss: 0.7621\tTrain accuracy: 70.81\tValid accuracy: 73.22\n",
            "Epoch: 26\tTrain loss: 0.8104\tValid loss: 0.7895\tTrain accuracy: 69.52\tValid accuracy: 73.13\n",
            "Epoch: 27\tTrain loss: 0.8011\tValid loss: 0.7659\tTrain accuracy: 71.01\tValid accuracy: 73.71\n",
            "Epoch: 28\tTrain loss: 0.7896\tValid loss: 0.7119\tTrain accuracy: 72.69\tValid accuracy: 75.57\n",
            "Epoch: 29\tTrain loss: 0.7811\tValid loss: 0.7334\tTrain accuracy: 72.18\tValid accuracy: 74.07\n",
            "Epoch: 30\tTrain loss: 0.7719\tValid loss: 0.7066\tTrain accuracy: 73.11\tValid accuracy: 75.02\n",
            "Epoch: 31\tTrain loss: 0.7654\tValid loss: 0.7288\tTrain accuracy: 72.42\tValid accuracy: 74.39\n",
            "Epoch: 32\tTrain loss: 0.7575\tValid loss: 0.7281\tTrain accuracy: 72.15\tValid accuracy: 74.49\n",
            "Epoch: 33\tTrain loss: 0.7497\tValid loss: 0.6791\tTrain accuracy: 74.35\tValid accuracy: 76.59\n",
            "Epoch: 34\tTrain loss: 0.7427\tValid loss: 0.7023\tTrain accuracy: 73.21\tValid accuracy: 75.40\n",
            "Epoch: 35\tTrain loss: 0.7306\tValid loss: 0.6673\tTrain accuracy: 75.01\tValid accuracy: 76.99\n",
            "Epoch: 36\tTrain loss: 0.7309\tValid loss: 0.6776\tTrain accuracy: 75.22\tValid accuracy: 76.63\n",
            "Epoch: 37\tTrain loss: 0.7224\tValid loss: 0.6593\tTrain accuracy: 75.40\tValid accuracy: 77.29\n",
            "Epoch: 38\tTrain loss: 0.7109\tValid loss: 0.7195\tTrain accuracy: 73.45\tValid accuracy: 75.34\n",
            "Epoch: 39\tTrain loss: 0.7124\tValid loss: 0.6631\tTrain accuracy: 75.82\tValid accuracy: 76.73\n",
            "Epoch: 40\tTrain loss: 0.7000\tValid loss: 0.6933\tTrain accuracy: 74.38\tValid accuracy: 75.54\n",
            "Epoch: 41\tTrain loss: 0.6947\tValid loss: 0.6725\tTrain accuracy: 75.43\tValid accuracy: 76.43\n",
            "Epoch: 42\tTrain loss: 0.6874\tValid loss: 0.6422\tTrain accuracy: 76.34\tValid accuracy: 77.69\n",
            "Epoch: 43\tTrain loss: 0.6837\tValid loss: 0.6339\tTrain accuracy: 76.91\tValid accuracy: 78.16\n",
            "Epoch: 44\tTrain loss: 0.6786\tValid loss: 0.6744\tTrain accuracy: 74.87\tValid accuracy: 76.62\n",
            "Epoch: 45\tTrain loss: 0.6694\tValid loss: 0.6196\tTrain accuracy: 77.41\tValid accuracy: 78.54\n",
            "Epoch: 46\tTrain loss: 0.6655\tValid loss: 0.6304\tTrain accuracy: 77.06\tValid accuracy: 78.23\n",
            "Epoch: 47\tTrain loss: 0.6567\tValid loss: 0.6629\tTrain accuracy: 76.14\tValid accuracy: 77.19\n",
            "Epoch: 48\tTrain loss: 0.6510\tValid loss: 0.6318\tTrain accuracy: 77.55\tValid accuracy: 78.07\n",
            "Epoch: 49\tTrain loss: 0.6482\tValid loss: 0.6259\tTrain accuracy: 77.72\tValid accuracy: 78.23\n",
            "Epoch: 50\tTrain loss: 0.6416\tValid loss: 0.6279\tTrain accuracy: 77.63\tValid accuracy: 78.38\n",
            "Epoch: 51\tTrain loss: 0.6399\tValid loss: 0.6085\tTrain accuracy: 78.08\tValid accuracy: 78.85\n",
            "Epoch: 52\tTrain loss: 0.6345\tValid loss: 0.6099\tTrain accuracy: 78.67\tValid accuracy: 78.94\n",
            "Epoch: 53\tTrain loss: 0.6271\tValid loss: 0.6323\tTrain accuracy: 77.15\tValid accuracy: 78.26\n",
            "Epoch: 54\tTrain loss: 0.6211\tValid loss: 0.5913\tTrain accuracy: 79.34\tValid accuracy: 79.35\n",
            "Epoch: 55\tTrain loss: 0.6210\tValid loss: 0.6040\tTrain accuracy: 78.76\tValid accuracy: 78.73\n",
            "Epoch: 56\tTrain loss: 0.6117\tValid loss: 0.6186\tTrain accuracy: 78.23\tValid accuracy: 78.90\n",
            "Epoch: 57\tTrain loss: 0.6121\tValid loss: 0.6329\tTrain accuracy: 77.92\tValid accuracy: 78.22\n",
            "Epoch: 58\tTrain loss: 0.6044\tValid loss: 0.5933\tTrain accuracy: 78.86\tValid accuracy: 79.37\n",
            "Epoch: 59\tTrain loss: 0.5956\tValid loss: 0.5955\tTrain accuracy: 79.19\tValid accuracy: 79.65\n",
            "Epoch: 60\tTrain loss: 0.5973\tValid loss: 0.5974\tTrain accuracy: 79.32\tValid accuracy: 79.61\n",
            "Epoch: 61\tTrain loss: 0.5903\tValid loss: 0.5990\tTrain accuracy: 78.89\tValid accuracy: 79.14\n",
            "Epoch: 62\tTrain loss: 0.5862\tValid loss: 0.5911\tTrain accuracy: 79.78\tValid accuracy: 79.37\n",
            "Epoch: 63\tTrain loss: 0.5850\tValid loss: 0.6085\tTrain accuracy: 78.75\tValid accuracy: 78.82\n",
            "Epoch: 64\tTrain loss: 0.5783\tValid loss: 0.5682\tTrain accuracy: 80.07\tValid accuracy: 80.50\n",
            "Epoch: 65\tTrain loss: 0.5772\tValid loss: 0.5697\tTrain accuracy: 80.56\tValid accuracy: 80.20\n",
            "Epoch: 66\tTrain loss: 0.5707\tValid loss: 0.6276\tTrain accuracy: 77.94\tValid accuracy: 78.27\n",
            "Epoch: 67\tTrain loss: 0.5678\tValid loss: 0.5647\tTrain accuracy: 80.82\tValid accuracy: 80.37\n",
            "Epoch: 68\tTrain loss: 0.5643\tValid loss: 0.5606\tTrain accuracy: 80.84\tValid accuracy: 80.61\n",
            "Epoch: 69\tTrain loss: 0.5595\tValid loss: 0.6641\tTrain accuracy: 76.66\tValid accuracy: 77.11\n",
            "Epoch: 70\tTrain loss: 0.5546\tValid loss: 0.5701\tTrain accuracy: 80.06\tValid accuracy: 80.02\n",
            "Epoch: 71\tTrain loss: 0.5558\tValid loss: 0.5797\tTrain accuracy: 80.14\tValid accuracy: 79.99\n",
            "Epoch: 72\tTrain loss: 0.5497\tValid loss: 0.5446\tTrain accuracy: 81.82\tValid accuracy: 81.23\n",
            "Epoch: 73\tTrain loss: 0.5455\tValid loss: 0.5646\tTrain accuracy: 80.89\tValid accuracy: 80.93\n",
            "Epoch: 74\tTrain loss: 0.5400\tValid loss: 0.5476\tTrain accuracy: 81.33\tValid accuracy: 80.91\n",
            "Epoch: 75\tTrain loss: 0.5415\tValid loss: 0.5611\tTrain accuracy: 81.51\tValid accuracy: 80.65\n",
            "Epoch: 76\tTrain loss: 0.5356\tValid loss: 0.5519\tTrain accuracy: 82.01\tValid accuracy: 80.99\n",
            "Epoch: 77\tTrain loss: 0.5308\tValid loss: 0.5862\tTrain accuracy: 79.98\tValid accuracy: 79.77\n",
            "Epoch: 78\tTrain loss: 0.5283\tValid loss: 0.5685\tTrain accuracy: 81.01\tValid accuracy: 80.52\n",
            "Epoch: 79\tTrain loss: 0.5257\tValid loss: 0.5730\tTrain accuracy: 81.67\tValid accuracy: 80.29\n",
            "Epoch: 80\tTrain loss: 0.5204\tValid loss: 0.6095\tTrain accuracy: 80.39\tValid accuracy: 78.99\n",
            "Epoch: 81\tTrain loss: 0.5195\tValid loss: 0.5703\tTrain accuracy: 81.04\tValid accuracy: 80.47\n",
            "Epoch: 82\tTrain loss: 0.5170\tValid loss: 0.5474\tTrain accuracy: 82.21\tValid accuracy: 81.13\n",
            "Epoch: 83\tTrain loss: 0.5123\tValid loss: 0.5485\tTrain accuracy: 82.46\tValid accuracy: 81.20\n",
            "Epoch: 84\tTrain loss: 0.5106\tValid loss: 0.5435\tTrain accuracy: 82.16\tValid accuracy: 81.43\n",
            "Epoch: 85\tTrain loss: 0.5093\tValid loss: 0.5854\tTrain accuracy: 81.23\tValid accuracy: 80.17\n",
            "Epoch: 86\tTrain loss: 0.5052\tValid loss: 0.5735\tTrain accuracy: 81.89\tValid accuracy: 80.64\n",
            "Epoch: 87\tTrain loss: 0.4969\tValid loss: 0.5574\tTrain accuracy: 81.59\tValid accuracy: 81.14\n",
            "Epoch: 88\tTrain loss: 0.4972\tValid loss: 0.5283\tTrain accuracy: 83.02\tValid accuracy: 81.90\n",
            "Epoch: 89\tTrain loss: 0.4955\tValid loss: 0.5269\tTrain accuracy: 83.32\tValid accuracy: 81.96\n",
            "Epoch: 90\tTrain loss: 0.4911\tValid loss: 0.5614\tTrain accuracy: 82.36\tValid accuracy: 80.99\n",
            "Epoch: 91\tTrain loss: 0.4928\tValid loss: 0.5747\tTrain accuracy: 81.88\tValid accuracy: 80.08\n",
            "Epoch: 92\tTrain loss: 0.4862\tValid loss: 0.5158\tTrain accuracy: 83.36\tValid accuracy: 82.02\n",
            "Epoch: 93\tTrain loss: 0.4848\tValid loss: 0.5326\tTrain accuracy: 83.55\tValid accuracy: 81.81\n",
            "Epoch: 94\tTrain loss: 0.4807\tValid loss: 0.5406\tTrain accuracy: 82.94\tValid accuracy: 81.39\n",
            "Epoch: 95\tTrain loss: 0.4814\tValid loss: 0.5235\tTrain accuracy: 83.40\tValid accuracy: 82.21\n",
            "Epoch: 96\tTrain loss: 0.4796\tValid loss: 0.5276\tTrain accuracy: 83.76\tValid accuracy: 81.95\n",
            "Epoch: 97\tTrain loss: 0.4702\tValid loss: 0.5237\tTrain accuracy: 83.68\tValid accuracy: 81.84\n",
            "Epoch: 98\tTrain loss: 0.4734\tValid loss: 0.5150\tTrain accuracy: 84.09\tValid accuracy: 82.23\n",
            "Epoch: 99\tTrain loss: 0.4693\tValid loss: 0.5611\tTrain accuracy: 82.38\tValid accuracy: 81.07\n"
          ]
        }
      ],
      "source": [
        "model, optimizer, (train_losses, valid_losses), (train_accuracies, valid_accuracies) = training_loop(model, criterion, optimizer,\n",
        "                                                                                                     train_loader, test_loader, EPOCHS, DEVICE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Accuracy and Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Nso-asIhS90N"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/m1/rvjhdxrd0jjg1f2vnlnwm7y40000gn/T/ipykernel_5201/1643168129.py:17: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
            "  plt.show()\n",
            "/var/folders/m1/rvjhdxrd0jjg1f2vnlnwm7y40000gn/T/ipykernel_5201/1643168129.py:33: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
            "  plt.show()\n"
          ]
        }
      ],
      "source": [
        "SAVE_PLOTS = False\n",
        "if SAVE_PLOTS:\n",
        "    matplotlib.use(\"Agg\")\n",
        "\n",
        "# Plot Loss\n",
        "plt.figure()\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.plot(range(len(train_losses)), train_losses, color=\"r\", label=\"Training\")\n",
        "plt.plot(range(len(valid_losses)), valid_losses, color=\"b\", label=\"Validation\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "if SAVE_PLOTS:\n",
        "    plt.savefig(\n",
        "        \"plots/centralised_LR[{}]_EPOCHS[{}]_BATCHNORM[{}]_GROUPNORM[{},{},{}]_loss.png\".format(LEARNING_RATE, EPOCHS, BATCH_NORM, GROUP_NORM, groupNormParams['groupNL1'], groupNormParams['groupNL2']))\n",
        "else:\n",
        "    plt.show()\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.figure()\n",
        "plt.title(\"Training and Validation Accuracy\")\n",
        "plt.plot(range(len(train_accuracies)),\n",
        "         train_accuracies, color=\"r\", label=\"Training\")\n",
        "plt.plot(range(len(valid_accuracies)), valid_accuracies,\n",
        "         color=\"b\", label=\"Validation\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "if SAVE_PLOTS:\n",
        "    plt.savefig(\n",
        "        \"plots/centralised_LR[{}]_EPOCHS[{}]_BATCHNORM[{}]_GROUPNORM[{},{},{}]_accuracy.png\".format(LEARNING_RATE, EPOCHS, BATCH_NORM, GROUP_NORM, groupNormParams['groupNL1'], groupNormParams['groupNL2']))\n",
        "else:\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOHbIqVnL0EicjZQKAFl3Mm",
      "collapsed_sections": [],
      "name": "centralisedModel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
