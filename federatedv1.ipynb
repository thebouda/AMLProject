{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import fedAvg\n",
    "from torchvision import datasets, transforms\n",
    "from lenet5 import LeNet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from tqdm import tqdm # progress bar, not really necessary\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for federated learning\n",
    "num_clients = 20 # number of total clients\n",
    "num_selected = 6 # number of  clients selected for the training \n",
    "num_rounds = 10\n",
    "\n",
    "# parameters\n",
    "EPOCHS = 10 # epochs defined by user\n",
    "LEARNING_RATE = 2e-3 \n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaders and transformations\n",
    "# Image augmentation \n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Normalizing the test images\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Loading CIFAR10 using torchvision.datasets\n",
    "#traindata = datasets.CIFAR10('./data', train=True, download=False,\n",
    "#                       transform= transform_train)\n",
    "traindata = datasets.CIFAR10('./data', train=True, download=False, \n",
    "                transform=transform_train)\n",
    "\n",
    "\n",
    "# Dividing the training data into num_clients, with each client having equal number of images\n",
    "traindata_split = torch.utils.data.random_split(traindata, [int(traindata.data.shape[0] / num_clients) for _ in range(num_clients)])\n",
    "\n",
    "\n",
    "# # Dividing the training data into num_clients, with each client having equal number of images\n",
    "traindata_split = torch.utils.data.random_split(traindata, [int(traindata.data.shape[0] \n",
    "                    / num_clients) for _ in range(num_clients)])\n",
    "# Creating a pytorch loader for a Deep Learning model\n",
    "# train_loader = torch.utils.data.DataLoader(traindata, batch_size=BATCH_SIZE, shuffle=True) \n",
    "\n",
    "# Creating a pytorch loader for a Deep Learning model\n",
    "train_loader = [torch.utils.data.DataLoader(x, batch_size=BATCH_SIZE, shuffle=True) for x in traindata_split]\n",
    "\n",
    "\n",
    "# Loading the test iamges and thus converting them into a test_loader\n",
    "test_loader = torch.utils.data.DataLoader(datasets.CIFAR10('./data', train=False, \n",
    "            transform=transforms.Compose([transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "            ), batch_size=BATCH_SIZE, shuffle=True)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we're not on cuda\n"
     ]
    }
   ],
   "source": [
    "if DEVICE == 'cuda':\n",
    "    modelChosen = LeNet().to(DEVICE)\n",
    "else:\n",
    "    modelChosen = LeNet()\n",
    "    print(\"we're not on cuda\")\n",
    "\n",
    "\n",
    "centralizedModel = modelChosen\n",
    "\n",
    "# list of models, model per device SELECTED ( same model for each device in our case)\n",
    "federatedModels =  [modelChosen for _ in range(num_selected)]\n",
    "\n",
    "for models in federatedModels:\n",
    "    models.load_state_dict(centralizedModel.state_dict())  # we initialize every model with the central\n",
    "\n",
    "\n",
    "optimizers = [torch.optim.SGD(model.parameters(), lr=LEARNING_RATE) for model in federatedModels]\n",
    "# NO CRITERION?\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for X, y_target in train_loader:\n",
    "        \n",
    "        # set gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # if there is a GPU\n",
    "\n",
    "        X = X.to(device)\n",
    "        y_target =y_target.to(device)\n",
    "\n",
    "        # prediction\n",
    "\n",
    "        # call model forward()\n",
    "        y_predict, _ = model(X)\n",
    "        # get loss\n",
    "        loss = criterion(y_predict, y_target)\n",
    "        running_loss += loss.item() * X.size(0)\n",
    "        \n",
    "        # adjusting weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return model, optimizer, epoch_loss\n",
    "\n",
    "def client_update(model, optimizer, train_loader,device,criterion ,epoch=5):\n",
    "    \"\"\"\n",
    "    This function updates/trains client model on client data\n",
    "    \"\"\"\n",
    "    # model.train()\n",
    "    for e in range(epoch):\n",
    "        model, optimizer, train_loss = train(train_loader, model,\n",
    "                                criterion, optimizer, device)\n",
    "\n",
    "\n",
    "\n",
    "        # for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #     # data, target = data, target\n",
    "        #     optimizer.zero_grad()\n",
    "        #     output = model(data)\n",
    "        #     loss = F.nll_loss(output, target) # The negative log likelihood loss\n",
    "        #     loss.backward()\n",
    "        #     optimizer.step()\n",
    "    # return loss.item()\n",
    "    print(train_loss)\n",
    "    return train_loss\n",
    "\n",
    "def server_aggregate(global_model, client_models):\n",
    "    \"\"\"\n",
    "    This function has aggregation method 'mean'\n",
    "    \"\"\"\n",
    "    ### This will take simple mean of the weights of models ###\n",
    "    global_dict = global_model.state_dict()\n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = torch.stack([client_models[i].state_dict()[k].float() for i in range(len(client_models))], 0).mean(0)\n",
    "        print(global_dict[k])\n",
    "    global_model.load_state_dict(global_dict)\n",
    "    for model in client_models:\n",
    "        model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "\n",
    "\n",
    "def get_accuracy(model, data_loader, device):\n",
    "    '''\n",
    "    Function for computing the accuracy of the predictions over the entire data_loader\n",
    "    '''\n",
    "    \n",
    "    correct_pred = 0 \n",
    "    n = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for X, y_true in data_loader:\n",
    "\n",
    "            X = X.to(device)\n",
    "            y_true = y_true.to(device)\n",
    "\n",
    "            _, y_prob = model(X)\n",
    "            _, predicted_labels = torch.max(y_prob, 1)\n",
    "\n",
    "            n += y_true.size(0)\n",
    "            correct_pred += (predicted_labels == y_true).sum()\n",
    "\n",
    "    return correct_pred.float() / n\n",
    "    \n",
    "def test(valid_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "\n",
    "    for X, y_target in valid_loader:\n",
    "        # if there is a GPU\n",
    "\n",
    "        X = X.to(device)\n",
    "        y_target = y_target.to(device)\n",
    "\n",
    "        # prediction and loss\n",
    "\n",
    "        # call model forward()\n",
    "        y_predict, _ = model(X)\n",
    "        # get loss\n",
    "        loss = criterion(y_predict, y_target)\n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "    return model, epoch_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m# why 0?\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_selected):\n\u001b[1;32m---> 15\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mclient_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfederatedModels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient_idx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     train_acc \u001b[38;5;241m=\u001b[39m get_accuracy(federatedModels[i], train_loader[client_idx[i]], DEVICE)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# print(train_loader[i])\u001b[39;00m\n",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36mclient_update\u001b[1;34m(model, optimizer, train_loader, device, criterion, epoch)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# model.train()\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch):\n\u001b[1;32m---> 35\u001b[0m     model, optimizer, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# for batch_idx, (data, target) in enumerate(train_loader):\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m#     # data, target = data, target\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m#     optimizer.zero_grad()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m#     optimizer.step()\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# return loss.item()\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_loss)\n",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, model, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m     20\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m X\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# adjusting weights\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     26\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader\u001b[38;5;241m.\u001b[39mdataset)\n",
      "File \u001b[1;32mc:\\Users\\baldo\\OneDrive\\Escritorio\\polito\\aml\\AMLProj\\AMLbastiens\\AMLProjectBastien\\venv\\lib\\site-packages\\torch\\_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\baldo\\OneDrive\\Escritorio\\polito\\aml\\AMLProj\\AMLbastiens\\AMLProjectBastien\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###### training #######\n",
    "###### List containing info about learning #########\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "acc_train = []\n",
    "acc_test_arr = []\n",
    "\n",
    "for r in range(num_rounds):\n",
    "    # select random clients\n",
    "    # we select in the total number of clients, a random array of clients of size num_selected at each round\n",
    "    client_idx = np.random.permutation(num_clients)[:num_selected]\n",
    "    \n",
    "    loss = 0 # why 0?\n",
    "    for i in range(num_selected):\n",
    "        loss += client_update(federatedModels[i], optimizers[i], train_loader[client_idx[i]],DEVICE,criterion, epoch=EPOCHS)\n",
    "        train_acc = get_accuracy(federatedModels[i], train_loader[client_idx[i]], DEVICE)\n",
    "\n",
    "        # print(train_loader[i])\n",
    "        print(train_acc)\n",
    "        print(loss)\n",
    "    losses_train.append(loss)\n",
    "    server_aggregate(centralizedModel, federatedModels)\n",
    "\n",
    "    test_loss= test(test_loader,centralizedModel,criterion, DEVICE) # Test global model on data\n",
    "    test_acc = get_accuracy(centralizedModel, test_loader, DEVICE)\n",
    "    \n",
    "    # print(test_acc)\n",
    "    losses_test.append(test_loss)\n",
    "    acc_test_arr.append(test_acc)\n",
    "    print('%d-th round' % r)\n",
    "\n",
    "    # print('average train loss %0.3g | test loss %0.3g | test acc: %0.3f' % (loss / num_selected, test_loss, test_acc))\n",
    "    print('average train loss %0.3g ' % (loss / num_selected))\n",
    "    print(test_loss)\n",
    "    print(type(test_loss))\n",
    "    print(' test loss %0.3g '%(test_loss))\n",
    "    print('test acc: %0.3f'% (test_acc))\n",
    "\n",
    "\n",
    "    # train_acc = get_accuracy(model, train_loader, device)\n",
    "    # test_acc = get_accuracy(model, test_loader, device)\n",
    "    # DOES NOT GET THE ACCURACY, CHECK WITH THE FUNCITON FROM THE FEDERATED LEARNING AAND COMPARE WITH CENTRALISED MODEL\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a605e0aa9ba0153468378976782e6a438b220bce716ba7043b32bc2b74e9bc8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
