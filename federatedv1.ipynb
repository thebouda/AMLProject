{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from lenet5 import LeNet\n",
    "\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "# import fedAvg\n",
    "# from tqdm import tqdm # progress bar, not really necessary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameters \n",
    "\n",
    "# Check if cuda is available\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Model Training Parameters \n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 2e-3 \n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Parameters for Federated :earning\n",
    "num_clients = 20 # number of total clients\n",
    "num_selected = 6 # number of  clients selected for the training \n",
    "num_rounds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for X, y_target in train_loader:\n",
    "        \n",
    "        # set gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # if there is a GPU\n",
    "\n",
    "        X = X.to(device)\n",
    "        y_target =y_target.to(device)\n",
    "\n",
    "        # prediction\n",
    "\n",
    "        # call model forward()\n",
    "        y_predict, _ = model(X)\n",
    "        # get loss\n",
    "        loss = criterion(y_predict, y_target)\n",
    "        running_loss += loss.item() * X.size(0)\n",
    "        \n",
    "        # adjusting weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return model, optimizer, epoch_loss\n",
    " \n",
    "def test(valid_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "\n",
    "    for X, y_target in valid_loader:\n",
    "        # if there is a GPU\n",
    "\n",
    "        X = X.to(device)\n",
    "        y_target = y_target.to(device)\n",
    "\n",
    "        # prediction and loss\n",
    "\n",
    "        # call model forward()\n",
    "        y_predict, _ = model(X)\n",
    "        # get loss\n",
    "        loss = criterion(y_predict, y_target)\n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "    return model, epoch_loss\n",
    " \n",
    "\n",
    "def get_accuracy(model, data_loader, device):\n",
    "    '''\n",
    "    Function for computing the accuracy of the predictions over the entire data_loader\n",
    "    '''\n",
    "    \n",
    "    correct_pred = 0 \n",
    "    n = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for X, y_true in data_loader:\n",
    "\n",
    "            X = X.to(device)\n",
    "            y_true = y_true.to(device)\n",
    "\n",
    "            _, y_prob = model(X)\n",
    "            _, predicted_labels = torch.max(y_prob, 1)\n",
    "\n",
    "            n += y_true.size(0)\n",
    "            correct_pred += (predicted_labels == y_true).sum()\n",
    "\n",
    "    return correct_pred.float() / n\n",
    " \n",
    "def client_update(model, optimizer, train_loader,device,criterion ,epoch=5):\n",
    "    \"\"\"\n",
    "    This function updates/trains client model on client data\n",
    "    \"\"\"\n",
    "    # model.train()\n",
    "    for e in range(epoch):\n",
    "        model, optimizer, train_loss = train(train_loader, model,\n",
    "                                criterion, optimizer, device)\n",
    "\n",
    "\n",
    "\n",
    "        # for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #     # data, target = data, target\n",
    "        #     optimizer.zero_grad()\n",
    "        #     output = model(data)\n",
    "        #     loss = F.nll_loss(output, target) # The negative log likelihood loss\n",
    "        #     loss.backward()\n",
    "        #     optimizer.step()\n",
    "    # return loss.item()\n",
    "    #print(train_loss)\n",
    "    return train_loss\n",
    "\n",
    "def server_aggregate(global_model, client_models):\n",
    "    \"\"\"\n",
    "    This function has aggregation method 'mean'\n",
    "    \"\"\"\n",
    "    ### This will take simple mean of the weights of models ###\n",
    "    global_dict = global_model.state_dict()\n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = torch.stack([client_models[i].state_dict()[k].float() for i in range(len(client_models))], 0).mean(0)\n",
    "        # print(global_dict[k])\n",
    "    global_model.load_state_dict(global_dict)\n",
    "    for model in client_models:\n",
    "        model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(centralizedModel, federatedModels, criterion, optimizers, train_loader, test_loader,\n",
    "                epochs, device, print_every=1):\n",
    "\n",
    "    global_train_losses = [] # train_loss\n",
    "    global_valid_losses = []\n",
    "\n",
    "    global_train_accuracies = [] # train_accuracy\n",
    "    global_valid_accuracies = []\n",
    "\n",
    "    for round in range(num_rounds):\n",
    "\n",
    "        # Select random clients\n",
    "        # Select in the total number of clients, a random array of clients of size num_selected at each round\n",
    "        client_idx = np.random.permutation(num_clients)[:num_selected]\n",
    "    \n",
    "        local_train_losses = [] # local_losses\n",
    "        local_train_accuracies = []\n",
    "        local_valid_losses = []\n",
    "        local_valid_accuracies = []\n",
    "\n",
    "        for i in range(num_selected):\n",
    "            # Train federated model locally in client i for num epochs = EPOCHS\n",
    "            local_train_loss = client_update(federatedModels[i], optimizers[i], train_loader[client_idx[i]],DEVICE,criterion, epoch=EPOCHS)\n",
    "            local_train_acc = get_accuracy(federatedModels[i], train_loader[client_idx[i]], DEVICE)\n",
    "\n",
    "            local_train_losses.append(local_train_loss)\n",
    "            local_train_accuracies.append(local_train_acc)\n",
    "\n",
    "            local_valid_loss = test(test_loader, federatedModels[i], criterion, DEVICE)[1]\n",
    "            local_valid_acc = get_accuracy(federatedModels[i], test_loader, DEVICE)\n",
    "\n",
    "            local_valid_losses.append(local_valid_loss)\n",
    "            local_valid_accuracies.append(local_valid_acc)\n",
    "\n",
    "        server_aggregate(centralizedModel, federatedModels)\n",
    "\n",
    "        # Calculate avg training loss over all selected users at each round\n",
    "        local_train_loss_avg = sum(local_train_losses) / len(local_train_losses)\n",
    "        global_train_losses.append(local_train_loss_avg)\n",
    "\n",
    "        # Calculate avg training accuracy over all selected users at each round \n",
    "        local_train_acc_avg = sum(local_train_accuracies) / len(local_train_accuracies)\n",
    "        global_train_accuracies.append(local_train_acc_avg)\n",
    "\n",
    "\n",
    "        # Calculate avg valid loss over all selected users at each round\n",
    "        local_valid_loss_avg = sum(local_valid_losses) / len(local_valid_losses)\n",
    "        global_valid_losses.append(local_valid_loss_avg)\n",
    "\n",
    "        # Calculate avg valid accuracy over all selected users at each round \n",
    "        local_valid_acc_avg = sum(local_valid_accuracies) / len(local_valid_accuracies)\n",
    "        global_valid_accuracies.append(local_valid_acc_avg)\n",
    "\n",
    "\n",
    "\n",
    "        # valid_loss = test(test_loader,centralizedModel,criterion, DEVICE)[1] # Test global model on data\n",
    "        #valid_acc = get_accuracy(centralizedModel, test_loader, DEVICE)\n",
    "    \n",
    "        #global_valid_losses.append(valid_loss)\n",
    "        #global_valid_accuracies.append(valid_acc)\n",
    "\n",
    "        #print('%d-th round' % r)\n",
    "        # print('average train loss %0.3g | test loss %0.3g | test acc: %0.3f' % (loss / num_selected, test_loss, test_acc))\n",
    "        #print('average train loss %0.3g ' % (loss / num_selected))\n",
    "        #print(test_loss)\n",
    "        #print(type(test_loss))\n",
    "        #print(' test loss %0.3g '%(test_loss))\n",
    "        #print('test acc: %0.3f'% (test_acc))\n",
    "        print(f'Round: {round}\\t'\n",
    "                f'Train loss: {local_train_loss_avg:.4f}\\t'\n",
    "                  f'Valid loss: {local_valid_loss_avg:.4f}\\t'\n",
    "                  f'Train accuracy: {100 * local_train_acc_avg:.2f}\\t'\n",
    "                  f'Valid accuracy: {100 * local_valid_acc_avg:.2f}')\n",
    "\n",
    "\n",
    "\n",
    "        # train_acc = get_accuracy(model, train_loader, device)\n",
    "        # test_acc = get_accuracy(model, test_loader, device)\n",
    "        # DOES NOT GET THE ACCURACY, CHECK WITH THE FUNCITON FROM THE FEDERATED LEARNING AAND COMPARE WITH CENTRALISED MODEL\n",
    "    \n",
    "    return centralizedModel, federatedModels, optimizers, (global_train_losses, global_valid_losses), (global_train_accuracies, global_valid_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaders and Transformations\n",
    "\n",
    "# Image augmentation \n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Normalizing the test images\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Loading CIFAR10 using torchvision.datasets\n",
    "traindata = datasets.CIFAR10('./data', train=True, download=False, \n",
    "                transform=transform_train)\n",
    "\n",
    "\n",
    "# Dividing the training data into num_clients, with each client having equal number of images\n",
    "traindata_split = torch.utils.data.random_split(traindata, [int(traindata.data.shape[0] \n",
    "                    / num_clients) for _ in range(num_clients)])\n",
    "                    \n",
    "# Creating a pytorch loader for a Deep Learning model\n",
    "train_loader = [torch.utils.data.DataLoader(x, batch_size=BATCH_SIZE, shuffle=True) for x in traindata_split]\n",
    "\n",
    "\n",
    "# Loading the test iamges and thus converting them into a test_loader\n",
    "test_loader = torch.utils.data.DataLoader(datasets.CIFAR10('./data', train=False, \n",
    "            transform=transforms.Compose([transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "            ), batch_size=BATCH_SIZE, shuffle=True)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Selection\n",
    "model = LeNet().to(DEVICE)\n",
    "centralizedModel = model\n",
    "\n",
    "# list of models, model per device SELECTED ( same model for each device in our case)\n",
    "federatedModels =  [model for _ in range(num_selected)]\n",
    "\n",
    "for models in federatedModels:\n",
    "    models.load_state_dict(centralizedModel.state_dict())  # we initialize every model with the central\n",
    "\n",
    "\n",
    "optimizers = [torch.optim.SGD(model.parameters(), lr=LEARNING_RATE) for model in federatedModels]\n",
    "# NO CRITERION?\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 0\tTrain loss: 1.9446\tValid loss: 1.9184\tTrain accuracy: 28.90\tValid accuracy: 30.55\n",
      "Round: 1\tTrain loss: 1.5873\tValid loss: 1.5727\tTrain accuracy: 40.51\tValid accuracy: 42.28\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/giuseppesalvi/Desktop/Advanced Machine Learning/project/AMLProject/federatedv1.ipynb Cell 7'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000005?line=0'>1</a>\u001b[0m \u001b[39m# Training \u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000005?line=1'>2</a>\u001b[0m centralizedModel, federatedModels, optimizers, (train_losses, valid_losses), (train_accuracies, valid_accuracies) \u001b[39m=\u001b[39m training_loop(centralizedModel, federatedModels, criterion, optimizers, train_loader, test_loader, EPOCHS, DEVICE)\n",
      "\u001b[1;32m/Users/giuseppesalvi/Desktop/Advanced Machine Learning/project/AMLProject/federatedv1.ipynb Cell 4'\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(centralizedModel, federatedModels, criterion, optimizers, train_loader, test_loader, epochs, device, print_every)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000009?line=18'>19</a>\u001b[0m local_valid_accuracies \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000009?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_selected):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000009?line=21'>22</a>\u001b[0m     \u001b[39m# Train federated model locally in client i for num epochs = EPOCHS\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000009?line=22'>23</a>\u001b[0m     local_train_loss \u001b[39m=\u001b[39m client_update(federatedModels[i], optimizers[i], train_loader[client_idx[i]],DEVICE,criterion, epoch\u001b[39m=\u001b[39;49mEPOCHS)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000009?line=23'>24</a>\u001b[0m     local_train_acc \u001b[39m=\u001b[39m get_accuracy(federatedModels[i], train_loader[client_idx[i]], DEVICE)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000009?line=25'>26</a>\u001b[0m     local_train_losses\u001b[39m.\u001b[39mappend(local_train_loss)\n",
      "\u001b[1;32m/Users/giuseppesalvi/Desktop/Advanced Machine Learning/project/AMLProject/federatedv1.ipynb Cell 3'\u001b[0m in \u001b[0;36mclient_update\u001b[0;34m(model, optimizer, train_loader, device, criterion, epoch)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000008?line=77'>78</a>\u001b[0m \u001b[39m# model.train()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000008?line=78'>79</a>\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epoch):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000008?line=79'>80</a>\u001b[0m     model, optimizer, train_loss \u001b[39m=\u001b[39m train(train_loader, model,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000008?line=80'>81</a>\u001b[0m                             criterion, optimizer, device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000008?line=84'>85</a>\u001b[0m     \u001b[39m# for batch_idx, (data, target) in enumerate(train_loader):\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000008?line=85'>86</a>\u001b[0m     \u001b[39m#     # data, target = data, target\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000008?line=86'>87</a>\u001b[0m     \u001b[39m#     optimizer.zero_grad()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000008?line=91'>92</a>\u001b[0m \u001b[39m# return loss.item()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000008?line=92'>93</a>\u001b[0m \u001b[39m#print(train_loss)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000008?line=93'>94</a>\u001b[0m \u001b[39mreturn\u001b[39;00m train_loss\n",
      "\u001b[1;32m/Users/giuseppesalvi/Desktop/Advanced Machine Learning/project/AMLProject/federatedv1.ipynb Cell 3'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000008?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000008?line=2'>3</a>\u001b[0m running_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000008?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m X, y_target \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000008?line=4'>5</a>\u001b[0m     \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000008?line=5'>6</a>\u001b[0m     \u001b[39m# set gradient to zero\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000008?line=6'>7</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/giuseppesalvi/Desktop/Advanced%20Machine%20Learning/project/AMLProject/federatedv1.ipynb#ch0000008?line=8'>9</a>\u001b[0m     \u001b[39m# if there is a GPU\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=518'>519</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=519'>520</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=520'>521</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=521'>522</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=522'>523</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=523'>524</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=524'>525</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=558'>559</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=559'>560</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=560'>561</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=561'>562</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=562'>563</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/utils/data/dataset.py:363\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/dataset.py?line=360'>361</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/dataset.py?line=361'>362</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[0;32m--> <a href='file:///opt/homebrew/lib/python3.9/site-packages/torch/utils/data/dataset.py?line=362'>363</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torchvision/datasets/cifar.py:121\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/torchvision/datasets/cifar.py?line=117'>118</a>\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img)\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/torchvision/datasets/cifar.py?line=119'>120</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/homebrew/lib/python3.9/site-packages/torchvision/datasets/cifar.py?line=120'>121</a>\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/torchvision/datasets/cifar.py?line=122'>123</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/torchvision/datasets/cifar.py?line=123'>124</a>\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torchvision/transforms/transforms.py:61\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=58'>59</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     <a href='file:///opt/homebrew/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=59'>60</a>\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> <a href='file:///opt/homebrew/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=60'>61</a>\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     <a href='file:///opt/homebrew/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=61'>62</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torchvision/transforms/transforms.py:98\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=89'>90</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m     <a href='file:///opt/homebrew/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=90'>91</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=91'>92</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=92'>93</a>\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=95'>96</a>\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=96'>97</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///opt/homebrew/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=97'>98</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torchvision/transforms/functional.py:148\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=145'>146</a>\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mview(pic\u001b[39m.\u001b[39msize[\u001b[39m1\u001b[39m], pic\u001b[39m.\u001b[39msize[\u001b[39m0\u001b[39m], \u001b[39mlen\u001b[39m(pic\u001b[39m.\u001b[39mgetbands()))\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=146'>147</a>\u001b[0m \u001b[39m# put it from HWC to CHW format\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/homebrew/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=147'>148</a>\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mpermute((\u001b[39m2\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m))\u001b[39m.\u001b[39;49mcontiguous()\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=148'>149</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mByteTensor):\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=149'>150</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39mto(dtype\u001b[39m=\u001b[39mdefault_float_dtype)\u001b[39m.\u001b[39mdiv(\u001b[39m255\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training \n",
    "centralizedModel, federatedModels, optimizers, (train_losses, valid_losses), (train_accuracies, valid_accuracies) = training_loop(centralizedModel, federatedModels, criterion, optimizers, train_loader, test_loader, EPOCHS, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting Accuracy and Loss\n",
    "\n",
    "SAVE_PLOTS = False# To save plots or show them\n",
    "if SAVE_PLOTS:\n",
    "    matplotlib.use(\"Agg\") \n",
    "\n",
    "# Plot Loss \n",
    "plt.figure()\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.plot(range(len(train_losses)), train_losses, color=\"r\", label=\"Training\")\n",
    "plt.plot(range(len(valid_losses)), valid_losses, color=\"b\", label=\"Validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "if SAVE_PLOTS:\n",
    "    plt.savefig(\"plots/centralised_LR[{}]_EPOCHS[{}]_loss.png\".format(LEARNING_RATE, EPOCHS)) \n",
    "else:\n",
    "    plt.show()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.figure()\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.plot(range(len(train_accuracies)), train_accuracies, color=\"r\", label=\"Training\")\n",
    "plt.plot(range(len(valid_accuracies)), valid_accuracies, color=\"b\", label=\"Validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "if SAVE_PLOTS:\n",
    "    plt.savefig(\"plots/centralised_LR[{}]_EPOCHS[{}]_accuracy.png\".format(LEARNING_RATE, EPOCHS))\n",
    "else:\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a605e0aa9ba0153468378976782e6a438b220bce716ba7043b32bc2b74e9bc8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
